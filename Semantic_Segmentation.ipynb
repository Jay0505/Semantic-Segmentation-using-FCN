{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3, 3, 64)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from SS_tf_var_funcs.ipynp import conv_layer\n",
    "from SS_tf_var_funcs.ipynp import pooling_layer\n",
    "from SS_tf_var_funcs.ipynp import fc_layer\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 100\n",
    "num_of_classes = np.shape(train_Y)[-1]\n",
    "\n",
    "        \n",
    "        \n",
    "def FCN(X):   \n",
    "    conv_1_1 = conv_layer(X, flt_name = 'conv1_1__W', bias_name = 'conv1_1_b', name = 'conv_1_1')\n",
    "    conv_1_2 = conv_layer(conv_1_1, flt_name = 'conv1_2_W', bias_name = 'conv1_2_b', name = 'conv_1_2')\n",
    "    pool_1   = pooling_layer(conv_1_2, name = 'pool_1')\n",
    "\n",
    "    conv_2_1 = conv_layer(pool_1, flt_name = 'conv2_1_W', bias_name = 'conv2_1_b', name = 'conv_2_1')\n",
    "    conv_2_2 = conv_layer(conv_2_1, flt_name = 'conv2_2_W', bias_name = 'conv2_2_b', name = 'conv_2_2')\n",
    "    pool_2   = pooling_layer(conv_2_2, name = 'pool_2')\n",
    "\n",
    "    conv_3_1 = conv_layer(pool_2, flt_name = 'conv3_1_W', bias_name = 'conv3_1_b', name = 'conv_3_1')\n",
    "    conv_3_2 = conv_layer(conv_3_1, flt_name = 'conv3_2_W', bias_name = 'conv3_2_b', name = 'conv_3_2')\n",
    "    conv_3_3 = conv_layer(conv_3_2, flt_name = 'conv3_3_W', bias_name = 'conv3_3_b', name = 'conv_3_3')\n",
    "    pool_3   = pooling_layer(conv_3_3, name = 'pool_3')\n",
    "\n",
    "    conv_4_1 = conv_layer(pool_3, flt_name = 'conv4_1_W', bias_name = 'conv4_1_b', name = 'conv_4_1')\n",
    "    conv_4_2 = conv_layer(conv_4_1, flt_name = 'conv4_2_W', bias_name = 'conv4_2_b', name = 'conv_4_2')\n",
    "    conv_4_3 = conv_lauyer(conv_4_2, flt_name = 'conv4_3_W', bias_name = 'conv4_3_b', name = 'conv_4_3')\n",
    "    pool_4   = pooling_layer(conv_4_3, name = 'pool_4')\n",
    "\n",
    "    conv_5_1 = conv_layer(pool_4, flt_name = 'conv5_1_W', bias_name = 'conv5_1_b', name = 'conv_5_1')\n",
    "    conv_5_2 = conv_layer(conv_5_1, flt_name = 'conv5_2_W', bias_name = 'conv5_2_b', name = 'conv_5_2')\n",
    "    conv_5_3 = conv_layer(conv_5_2, flt_name = 'conv5_3_W', bias_name = 'conv5_3_b', name = 'conv_5_3')\n",
    "    pool_5   = pooling_layer(conv_5_3, name = 'pool_5')\n",
    "\n",
    "    fc_1     = fc_layer(pool_5, 'fc6_W', 'fc6_b')\n",
    "    fc_2     = fc_layer(fc_1, 'fc7_W', 'fc7_b')\n",
    "    fc_3     = fc_layer(fc_2)\n",
    "\n",
    "\n",
    "    upsample_op_shape    = [batch_size, img_height, img_width, num_of_classes]\n",
    "    fc3_upsample         = upsample(fc_3, upsample_op_shape, num_of_classes, 'fc3_upsmp', 32)\n",
    "\n",
    "    pool4_skip_flt_shape = [1, 1, np.shape(pool_4)[-1], num_of_classes]\n",
    "    pool3_skip_flt_shape = [1, 1, np.shape(pool_3)[-1], num_of_classes]\n",
    "\n",
    "    pool4_skip           = skip_connection(pool_4, 'pool4_skip', pool4_skip_flt_shape)\n",
    "    pool4_upsample       = upsample(pool4_skip, upsample_op_shape, num_of_classes, 'pool4_upsmp', 16)\n",
    "\n",
    "    pool3_skip           = skip_connection(pool_3, 'pool3_skip', pool3_skip_flt_shape)\n",
    "    pool3_upsample       = upsample(pool3_skip, upsample_op_shape, num_of_classes, 'pool3_upsmp', 8)\n",
    "\n",
    "    logits = tf.add(fc3_upsample, tf.add(2 * pool4_upsample, 4 * pool3_upsample))\n",
    "\n",
    "    return logits\n",
    "    \n",
    "        \n",
    "\n",
    "def train_optimizer(x_batch, y_batch):\n",
    "    FCN_logits = FCN(x_batch)\n",
    "    cost = logistic_loss(logits=FCN_logits, labels=y_batch, n_classes=num_of_classes)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = 0.001).minimize(cost)\n",
    "    \n",
    "    return FCN_logits, cost, optimizer\n",
    "\n",
    "\n",
    "def run_FCN_model():\n",
    "    with tf.Session() as session:\n",
    "        x_ph, y_ph, dropout   = get_placeholders_for_train_label_data()\n",
    "        FCN_logits, loss, optimizer = train_optimizer(x_ph, y_ph)\n",
    "        \n",
    "        session.run(tf.global_variables_initializer())\n",
    "        saver = tf.train.saver(tf.trainable_variables())\n",
    "        \n",
    "        for epoch in range(0, 1):\n",
    "            for i in range(0, len(train_X), batch_size):\n",
    "                train_x = train_X[i : i + batch_size]\n",
    "                train_y = train_Y[i : i + batch_size]\n",
    "                _, loss = session.run([optimizer, loss], feed_dict = {x_ph : train_x,\n",
    "                                                                      y_ph : train_y})\n",
    "                \n",
    "        \n",
    "        save_path = saver.save(session, \"./SS_FCN_model\")\n",
    "        \n",
    "    return FCN_logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
