{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import random\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "############################################\n",
    "\n",
    "\n",
    "def get_label_color_values(label_folder_path):\n",
    "    label_images_names = os.listdir(label_folder_path)\n",
    "    rgb_values = get_pixel_RGB_values(label_folder_path + '/' + label_images_names[0])\n",
    "    \n",
    "    return rgb_values\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "############################################\n",
    "\n",
    "\n",
    "def get_pixel_RGB_values(path):\n",
    "    im = Image.open(path)\n",
    "    rgb_values = []\n",
    "    pix = im.load()\n",
    "    \n",
    "    return list(set(list(im.getdata())))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "############################################\n",
    "\n",
    "\n",
    "def label_image_to_one_hot(image, label_values):\n",
    "    semantic_map = []\n",
    "    for colour in label_values:\n",
    "        # colour_map = np.full((label.shape[0], label.shape[1], label.shape[2]), colour, dtype=int)\n",
    "        equality = np.equal(image, colour)\n",
    "        class_map = np.all(equality, axis = -1)\n",
    "        semantic_map.append(class_map)\n",
    "    semantic_map = np.stack(semantic_map, axis=-1)\n",
    "\n",
    "    return semantic_map\n",
    "\n",
    "\n",
    "\n",
    "############################################\n",
    "\n",
    "\n",
    "def get_input_batches_(images_path, labels_path):\n",
    "    \n",
    "    def generate_batches(batch_size, label_values):\n",
    "        count = 0\n",
    "        images_names = os.listdir(images_path)\n",
    "        total_no_of_images = len(images_names)\n",
    "        background = np.array([255, 0, 0])\n",
    "        random.shuffle(images_names)\n",
    "        for index in range(0, total_no_of_images, batch_size):\n",
    "            images_arr = []\n",
    "            labels_arr = []\n",
    "            for image_name in images_names[index : index + batch_size]:\n",
    "                name_split = image_name.split('_')\n",
    "                label_name = name_split[0] + '_road_' + name_split[1]\n",
    "                \n",
    "                image = cv2.resize(cv2.imread(images_path + \"/\" + image_name), (612, 184))\n",
    "#                 image = image / 255.0\n",
    "                \n",
    "                label = cv2.resize(cv2.imread(labels_path + \"/\" + label_name), (612, 184))\n",
    "#                 label = label_image_to_one_hot(label, label_values)\n",
    "                gt_bg = np.all(label == background, axis=2)\n",
    "                gt_bg = gt_bg.reshape(*gt_bg.shape, 1)\n",
    "                gt_image = np.concatenate((gt_bg, np.invert(gt_bg)), axis=2)\n",
    "\n",
    "        \n",
    "     \n",
    "                \n",
    "                images_arr.append(image)\n",
    "                labels_arr.append(gt_image)\n",
    "#                 print(np.shape(image), np.shape(label))\n",
    "            yield np.array(images_arr), np.array(labels_arr)\n",
    "    \n",
    "    return generate_batches\n",
    "  \n",
    "  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_values = get_label_color_values('/Users/vijay/Downloads/Datasets/data_road/training/gt_image_2/')\n",
    "\n",
    "get_batches_ = get_input_batches_('/Users/vijay/Downloads/Datasets/data_road/training/image_2/', \n",
    "                                 '/Users/vijay/Downloads/Datasets/data_road/training/gt_image_2/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "VGG_16_weights_dict = np.load('/Users/vijay/Downloads/vgg16_weights.npz')\n",
    "num_of_classes = len(label_values)\n",
    "\n",
    "############################################\n",
    "\n",
    "def get_placeholders_for_train_label_data(no_of_classes):\n",
    "    \n",
    "    x       = tf.placeholder(tf.float32, shape = [None, 224 * 224 * 3], name = 'x_rs')\n",
    "    x_rs    = tf.reshape(x, shape = [-1, 224, 224, 3])\n",
    "    \n",
    "    y       = tf.placeholder(tf.float32, shape = [None, no_of_classes])\n",
    "    y_rs    = tf.reshape(y, shape = [-1, no_of_classes])\n",
    "    dropout = tf.placeholder(tf.float32, name = 'dropout')\n",
    "    \n",
    "    return x_rs, y_rs, dropout\n",
    "\n",
    "\n",
    "############################################\n",
    "\n",
    "def get_scale_and_gamma_variables(shape):\n",
    "\n",
    "    scale = tf.Variable(tf.ones(shape))\n",
    "    offset = tf.Variable(tf.zeros(shape))\n",
    "    \n",
    "    return scale, offset\n",
    "\n",
    "\n",
    "\n",
    "############################################\n",
    "\n",
    "def batch_normalize(data, shape):\n",
    "\n",
    "    scale, offset = get_scale_and_gamma_variables(shape)\n",
    "    mean, var     = tf.nn.moments(data, axes = [0, 1, 2])\n",
    "    data_norm     = tf.nn.batch_normalization(data, mean, var, scale, offset, 0.05, name = \"BN\")\n",
    "    \n",
    "    return data_norm\n",
    "  \n",
    "  \n",
    "  \n",
    "\n",
    "############################################\n",
    "\n",
    "def get_weights_or_bias_from_VGG(wts_or_bias_name):\n",
    "    return VGG_16_weights_dict[wts_or_bias_name]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############################################\n",
    "\n",
    "def get_weights_or_bias_as_variables(wts_or_bias_name):\n",
    "   \n",
    "    wts_or_bias    = get_weights_or_bias_from_VGG(wts_or_bias_name)\n",
    "    wt_or_bias_init = tf.constant_initializer(value = wts_or_bias, dtype = tf.float32)\n",
    "    wt_or_bias_var  = tf.get_variable(shape = np.shape(wts_or_bias), initializer = wt_or_bias_init, \n",
    "                                                                                  name = wts_or_bias_name)\n",
    "\n",
    "    return wt_or_bias_var\n",
    "\n",
    "\n",
    "\n",
    "############################################\n",
    "\n",
    "def fetch_and_reshape_fc_weights(fc_wts_name, rs_shape):\n",
    "    fc_wts      = VGG_16_weights_dict[fc_wts_name]\n",
    "    fc_wts      = fc_wts.reshape(rs_shape)\n",
    "    fc_wts_init = tf.constant_initializer(value = fc_wts, dtype = tf.float32)\n",
    "    fc_wts_var  = tf.get_variable(shape = rs_shape, initializer = fc_wts_init, name = 'fc_wts')\n",
    "    \n",
    "    return fc_wts_var\n",
    "\n",
    "\n",
    "\n",
    "############################################\n",
    "\n",
    "def conv_layer(data, flt_name, bias_name, name):\n",
    "\n",
    "    with tf.variable_scope(name, reuse=tf.AUTO_REUSE):\n",
    "        conv_wt       = get_weights_or_bias_as_variables(flt_name)\n",
    "        conv_bias     = get_weights_or_bias_as_variables(bias_name)\n",
    "\n",
    "        conv_res      = tf.nn.conv2d(data, filter = conv_wt, strides = [1, 1, 1, 1], padding = 'SAME')\n",
    "        conv_res_bias = tf.nn.bias_add(conv_res, conv_bias)\n",
    "        conv_bn       = batch_normalize(conv_res_bias, conv_res_bias.get_shape().as_list()[-1])\n",
    "        conv_res_relu = tf.nn.relu(conv_bn)\n",
    "\n",
    "        return conv_res_relu\n",
    "\n",
    "\n",
    "\n",
    "############################################\n",
    "\n",
    "def pooling_layer(data, pool_name):\n",
    "    with tf.variable_scope(pool_name, reuse = tf.AUTO_REUSE):\n",
    "        return tf.nn.max_pool(value = data, ksize = [1, 2, 2, 1], strides = [1, 2, 2, 1], padding = 'SAME')\n",
    "\n",
    "    \n",
    "\n",
    "############################################\n",
    "\n",
    "def fc_layer(data, dropout, fc_wts_name = None, fc_bias_name = None):\n",
    "    \n",
    "    with tf.variable_scope(fc_wts_name, reuse = tf.AUTO_REUSE):\n",
    "        \n",
    "        \n",
    "        if fc_wts_name != 'fc8_W':\n",
    "            fc_wt_shape = []\n",
    "            if fc_wts_name == 'fc6_W': \n",
    "                fc_wt_shape      = [7, 7, 512, 4096]\n",
    "                \n",
    "            if fc_wts_name == 'fc7_W':\n",
    "                fc_wt_shape      = [1, 1, 4096, 4096]\n",
    "\n",
    "            fc_wts       = fetch_and_reshape_fc_weights(fc_wts_name, fc_wt_shape)            \n",
    "            fc_bias      = get_weights_or_bias_as_variables(fc_bias_name)\n",
    "\n",
    "            fc_conv      = tf.nn.conv2d(data, filter = fc_wts, strides = [1, 1, 1, 1], padding = 'SAME')\n",
    "            fc_conv_bias = tf.nn.bias_add(fc_conv, fc_bias)\n",
    "            fc_conv_relu = tf.nn.relu(fc_conv_bias)\n",
    "            return tf.nn.dropout(fc_conv_relu, rate = dropout)\n",
    "\n",
    "        elif fc_wts_name == 'fc8_W':\n",
    "            initial      = tf.truncated_normal([1, 1, 4096, num_of_classes], stddev=0.0001)\n",
    "            kernel       = tf.get_variable('kernel', initializer=initial)\n",
    "            conv         = tf.nn.conv2d(data, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "            bias         = tf.Variable(tf.constant(0.1, shape = [num_of_classes]), name = 'bias')\n",
    "            return tf.nn.bias_add(conv, bias)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "############################################\n",
    "\n",
    "def skip_connection(from_data, con_name, flt_val, num_classes):\n",
    "    with tf.variable_scope(con_name, reuse=tf.AUTO_REUSE):\n",
    "        skp_wt = tf.Variable(tf.truncated_normal(flt_val, stddev = 0.2, seed = 23, dtype = tf.float32), name = 'skip_wt')\n",
    "        skp_conv = tf.nn.conv2d(from_data, skp_wt, [1, 1, 1, 1], padding = 'SAME')\n",
    "        \n",
    "        skp_bias = tf.Variable(tf.constant(0.1, shape = [num_classes], dtype = tf.float32), name = 'skip_bias')\n",
    "        skip_res = tf.nn.bias_add(skp_conv, skp_bias)\n",
    "        return skip_res\n",
    "\n",
    "    \n",
    "\n",
    "############################################\n",
    "\n",
    "def upsample(from_data, op_shape, no_of_channels, name, factor, num_classes):\n",
    "    flt_size = 2 * factor - factor % 2\n",
    "    strides = [1, factor, factor, 1]\n",
    "    with tf.variable_scope(name, reuse=tf.AUTO_REUSE):\n",
    "        filter_shape = [flt_size, flt_size, no_of_channels, no_of_channels]\n",
    "        weights = get_bilinear_weights(filter_shape, factor)\n",
    "        deconv = tf.nn.conv2d_transpose(from_data, weights, op_shape, strides = strides, padding = 'SAME')\n",
    "        \n",
    "        bias_init = tf.constant_initializer(0.1)\n",
    "        \n",
    "        upsmp_bias = tf.get_variable(initializer = bias_init, shape = [num_classes], name = 'upsmp_bias')\n",
    "        \n",
    "        deconv_bias = tf.nn.bias_add(deconv, upsmp_bias)\n",
    "        \n",
    "    return deconv_bias\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############################################\n",
    "\n",
    "def get_bilinear_weights(filter_shape, factor):\n",
    "#     print('filter_shape is ' + str(filter_shape))\n",
    "    flt_size = filter_shape[1]\n",
    "    if flt_size % 2 == 0:\n",
    "        centre = factor - 1\n",
    "    else:\n",
    "        centre = factor - 0.5\n",
    "        \n",
    "    bilinear = np.zeros([filter_shape[0], filter_shape[1]])\n",
    "    weights = np.zeros(filter_shape)\n",
    "#     print('weights shape is ' + str(np.shape(weights)))\n",
    "    for row in range(filter_shape[0]):\n",
    "        for column in range(filter_shape[1]):\n",
    "            cell_val = (1 - abs((row - centre) / factor)) * (1 - abs((column - centre) / factor))\n",
    "            bilinear[row, column] = cell_val\n",
    "    \n",
    "    for val in range(filter_shape[2]):\n",
    "        weights[:, :, val, val] = bilinear\n",
    "    \n",
    "    wt_init = tf.constant_initializer(value = weights, dtype = tf.float32)\n",
    "    bilinear_weights = tf.get_variable(initializer = wt_init, name = 'blnr_wt', shape = filter_shape)\n",
    "    \n",
    "    return bilinear_weights\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101, 720, 960, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "x           = tf.placeholder(tf.float32, shape = [None, 184, 612, 3], name = 'x_ph')\n",
    "y           = tf.placeholder(tf.float32, shape = [None, 184, 612, num_of_classes], name = 'y_ph')\n",
    "dropout     = tf.placeholder(tf.float32, name = 'dropout')\n",
    "global_step = tf.Variable(0, dtype=tf.int32, trainable=False, name='global_step')\n",
    "\n",
    "##########################################################\n",
    "        \n",
    "def FCN():\n",
    "  \n",
    "  \n",
    "        \n",
    "    with tf.variable_scope('FCN', reuse = tf.AUTO_REUSE):\n",
    "\n",
    "\n",
    "        conv_1_1 = conv_layer(x, flt_name = 'conv1_1_W', bias_name = 'conv1_1_b', name = 'conv_1_1')\n",
    "        conv_1_2 = conv_layer(conv_1_1, flt_name = 'conv1_2_W', bias_name = 'conv1_2_b',  name = 'conv_1_2')\n",
    "        pool_1   = pooling_layer(conv_1_2, pool_name = 'pool_1')\n",
    "\n",
    "\n",
    "        conv_2_1 = conv_layer(pool_1, flt_name = 'conv2_1_W', bias_name = 'conv2_1_b', name = 'conv_2_1')\n",
    "        conv_2_2 = conv_layer(conv_2_1, flt_name = 'conv2_2_W', bias_name = 'conv2_2_b', name = 'conv_2_2')\n",
    "        pool_2   = pooling_layer(conv_2_2, pool_name = 'pool_2')\n",
    "\n",
    "        conv_3_1 = conv_layer(pool_2, flt_name = 'conv3_1_W', bias_name = 'conv3_1_b', name = 'conv_3_1')\n",
    "        conv_3_2 = conv_layer(conv_3_1, flt_name = 'conv3_2_W', bias_name = 'conv3_2_b', name = 'conv_3_2')\n",
    "        conv_3_3 = conv_layer(conv_3_2, flt_name = 'conv3_3_W', bias_name = 'conv3_3_b', name = 'conv_3_3')\n",
    "        pool_3   = pooling_layer(conv_3_3, pool_name = 'pool_3')\n",
    "\n",
    "        conv_4_1 = conv_layer(pool_3, flt_name = 'conv4_1_W', bias_name = 'conv4_1_b', name = 'conv_4_1')\n",
    "        conv_4_2 = conv_layer(conv_4_1, flt_name = 'conv4_2_W', bias_name = 'conv4_2_b', name = 'conv_4_2')\n",
    "        conv_4_3 = conv_layer(conv_4_2, flt_name = 'conv4_3_W', bias_name = 'conv4_3_b', name = 'conv_4_3')\n",
    "        pool_4   = pooling_layer(conv_4_3, pool_name = 'pool_4')\n",
    "\n",
    "        conv_5_1 = conv_layer(pool_4, flt_name = 'conv5_1_W', bias_name = 'conv5_1_b', name = 'conv_5_1')\n",
    "        conv_5_2 = conv_layer(conv_5_1, flt_name = 'conv5_2_W', bias_name = 'conv5_2_b', name = 'conv_5_2')\n",
    "        conv_5_3 = conv_layer(conv_5_2, flt_name = 'conv5_3_W', bias_name = 'conv5_3_b', name = 'conv_5_3')\n",
    "        pool_5   = pooling_layer(conv_5_3, pool_name = 'pool_5')\n",
    "\n",
    "        fc_1     = fc_layer(pool_5, dropout, 'fc6_W', 'fc6_b')\n",
    "        fc_2     = fc_layer(fc_1, dropout, 'fc7_W', 'fc7_b')\n",
    "\n",
    "        fc_3     = fc_layer(fc_2, dropout, 'fc8_W', 'fc8_b')\n",
    "\n",
    "\n",
    "        batch_shape = x.get_shape().as_list()\n",
    "        upsample_op_shape    = tf.stack([batch_size, batch_shape[1], batch_shape[2], num_of_classes])\n",
    "        fc3_upsample         = upsample(fc_3, upsample_op_shape, num_of_classes, 'fc3_upsmp', 32, num_of_classes)\n",
    "\n",
    "        pool4_skip_flt_shape = tf.stack([1, 1, np.shape(pool_4)[-1], num_of_classes])\n",
    "        pool3_skip_flt_shape = tf.stack([1, 1, np.shape(pool_3)[-1], num_of_classes])\n",
    "\n",
    "        pool4_skip           = skip_connection(pool_4, 'pool4_skip', pool4_skip_flt_shape, num_of_classes)\n",
    "        pool4_upsample       = upsample(pool4_skip, upsample_op_shape, num_of_classes, 'pool4_upsmp', 16, num_of_classes)\n",
    "\n",
    "        pool3_skip           = skip_connection(pool_3, 'pool3_skip', pool3_skip_flt_shape, num_of_classes)\n",
    "        pool3_upsample       = upsample(pool3_skip, upsample_op_shape, num_of_classes, 'pool3_upsmp', 8, num_of_classes)\n",
    "\n",
    "        logits = tf.add(fc3_upsample, tf.add(2 * pool4_upsample, 4 * pool3_upsample))\n",
    "\n",
    "\n",
    "    return logits\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "##########################################################\n",
    "    \n",
    "def logistic_loss(logits, labels, n_classes):\n",
    "    \n",
    "    with tf.variable_scope('logistic_loss'):\n",
    "        \n",
    "        reshaped_logits = tf.reshape(logits, (-1, n_classes))\n",
    "        reshaped_labels = tf.reshape(labels, (-1, n_classes))\n",
    "        entropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits=reshaped_logits,\n",
    "                                                          labels=reshaped_labels)\n",
    "        loss = tf.reduce_mean(entropy, name='logistic_loss')\n",
    "        return loss\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "##########################################################\n",
    "\n",
    "\n",
    "def build_loss_summary(loss):\n",
    "    \n",
    "    with tf.variable_scope('loss_summary'):\n",
    "        tf.summary.scalar('loss', loss)\n",
    "        tf.summary.histogram('h_loss', loss)\n",
    "        return tf.summary.merge_all()\n",
    "    \n",
    "    \n",
    "##########################################################\n",
    "\n",
    "\n",
    "def train_optimizer():\n",
    "  \n",
    "  with tf.variable_scope('optim', reuse = tf.AUTO_REUSE):\n",
    "    FCN_logits = FCN()\n",
    "    cost = logistic_loss(logits=FCN_logits, labels=y, n_classes=num_of_classes)\n",
    "    \n",
    "#     cost = tf.reduce_mean(tf.square(y - FCN_logits))\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = 0.00001).minimize(cost, global_step = global_step)\n",
    "    \n",
    "    return FCN_logits, cost, optimizer\n",
    "\n",
    "\n",
    "  \n",
    "  \n",
    "  \n",
    "##########################################################\n",
    "\n",
    "def substract_the_mean(images):\n",
    "    mean = np.array([123.68, 116.779, 103.939]).reshape([1, 1, 1, 3]).astype(np.float32)\n",
    "    return images - mean\n",
    "\n",
    "\n",
    "  \n",
    "##########################################################\n",
    "\n",
    "\n",
    "def run_FCN_model():\n",
    "    \n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    count = 0\n",
    "    with tf.Session(config = config) as session:\n",
    "        \n",
    "        FCN_logits, loss, optimizer = train_optimizer()\n",
    "        loss_summary = build_loss_summary(loss)\n",
    "        session.run(tf.global_variables_initializer())\n",
    "        saver = tf.train.Saver(keep_checkpoint_every_n_hours = 0.5)\n",
    "        writer = tf.summary.FileWriter('./graphs/', session.graph)\n",
    "\n",
    "        for epoch in range(0, 1):\n",
    "            \n",
    "            images, labels = next(get_batches_(batch_size, label_values))\n",
    "            s_images = substract_the_mean(images)\n",
    "\n",
    "            _, loss_, summary = session.run([optimizer, loss, loss_summary], feed_dict = {x : s_images,\n",
    "                                                                                         y : labels, \n",
    "                                                                                         dropout : 0.75})\n",
    "\n",
    "            writer.add_summary(summary, global_step = epoch)\n",
    "            print(epoch, loss_ / batch_size)\n",
    "            if epoch % 100 == 0:\n",
    "                print('saved')\n",
    "                save_path = saver.save(session, \"./SS_FCN_model\", epoch)\n",
    "\n",
    "    return FCN_logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/envs/tensorflow-session/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "0 3.0746020911465166e-06\n",
      "saved\n"
     ]
    }
   ],
   "source": [
    "FCN_logits = run_FCN_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_batch(test_file_path):\n",
    "    \n",
    "    def get_batch(batch_size):\n",
    "        count = 0\n",
    "        images_names = os.listdir(test_file_path)\n",
    "        total_no_of_images = len(images_names)\n",
    "   \n",
    "        for index in range(0, total_no_of_images, batch_size):\n",
    "            \n",
    "        \n",
    "            images_arr = []\n",
    "    \n",
    "            for image_name in images_names[index : index + batch_size]:\n",
    "                \n",
    "        \n",
    "                image = cv2.resize(cv2.imread(test_file_path + \"/\" + image_name), (612, 184))\n",
    "#             image = image / 255.0\n",
    "            \n",
    "#                 if count < 8:\n",
    "#                     plt.figure(figsize=(10, 10))\n",
    "# #                     plt.imshow(image)\n",
    "#                     plt.imshow(label)\n",
    "#                     count = count + 1\n",
    "                images_arr.append(image)\n",
    "   \n",
    "            yield np.asarray(images_arr)\n",
    "    return get_batch\n",
    "\n",
    "\n",
    "get_test_images = get_test_batch('/Users/vijay/Downloads/Datasets/data_road/testing/image_2/')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "from PIL import Image\n",
    "import scipy.misc\n",
    "\n",
    "batch_size = 8\n",
    "no_of_test_images = 290\n",
    "\n",
    "def reverse_one_hot_to_colors(img):\n",
    "    x = np.argmax(img, axis = -1)\n",
    "    return x\n",
    "\n",
    "\n",
    "def color_code_segmentation(image, label_values):\n",
    "    colour_codes = np.array(label_values)\n",
    "    x = colour_codes[image.astype(int)]\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def pred_to_image(session, image, original):\n",
    "    \n",
    "    count = 0\n",
    "    im_softmax_ = session.run([tf.nn.softmax(image)], feed_dict = {x : original, dropout : 0.5})\n",
    "    print('im_softmax ' + str(np.shape(im_softmax_)))\n",
    "    for pred in im_softmax_[0]:\n",
    "        \n",
    "        print('pred shape ' + str(np.shape(pred[:, :, 1])))\n",
    "        pred = pred[:, :, 0].reshape(184, 612)\n",
    "        segmentation = (pred > 0.5).reshape(184, 612, 1)\n",
    "        mask = np.dot(segmentation, np.array([[221, 28, 199, 127]]))\n",
    "        mask = Image.fromarray(mask, mode=\"RGBA\")\n",
    "        print('original count ' + str(np.shape(original[count])))\n",
    "        street_im = Image.fromarray(np.uint8(original[count]))\n",
    "        street_im.paste(mask, box=None, mask=mask)\n",
    "        cv2.imwrite(('./' + str(count) + '.png'), cv2.cvtColor(np.uint8(street_im), cv2.COLOR_RGB2BGR))\n",
    "        count = count + 1\n",
    "\n",
    "def make_predictions(dropout_rate):\n",
    "    \n",
    "    count = 0\n",
    "    total_test_images = os.listdir('/Users/vijay/Downloads/Datasets/data_road/testing/image_2/')\n",
    "    with tf.Session() as session:\n",
    "        \n",
    "      \n",
    "        meta_graph = tf.train.import_meta_graph('./SS_FCN_model-0.meta')\n",
    "        meta_graph.restore(session, tf.train.latest_checkpoint('./'))\n",
    "        total_batches = int(no_of_test_images / batch_size)\n",
    "        for batch_no in range(total_batches):\n",
    "            \n",
    "            if batch_no < 1:\n",
    "                images = next(get_test_images(batch_size))\n",
    "                print('before FCN_logits ' + str(FCN_logits.get_shape().as_list()))\n",
    "                reshape_logits = tf.reshape(FCN_logits, (-1, num_of_classes))\n",
    "                print('after FCN_logits ' + str(reshape_logits.get_shape().as_list()))\n",
    "            \n",
    "                im = substract_the_mean(images)\n",
    "                pred_to_image(session, FCN_logits, im)\n",
    "\n",
    "            \n",
    "#             \n",
    "#                 prediction = session.run([tf.nn.softmax(FCN_logits)], feed_dict = {x : im, dropout : dropout_rate})\n",
    "\n",
    "#                 image_no = 0\n",
    "#                 for pred in prediction[0]:\n",
    "                \n",
    "\n",
    "#                     output_image = reverse_one_hot_to_colors((pred))\n",
    "#                     out_vis_image = color_code_segmentation(output_image, label_values)\n",
    "#                     cv2.imwrite(('./' + str(count) + '.png'),cv2.cvtColor(np.uint8(out_vis_image), cv2.COLOR_RGB2BGR))\n",
    "\n",
    "\n",
    "#                     count = count + 1\n",
    "#                     print('saved image ' + str(count) + '.png')\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_predictions(0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
